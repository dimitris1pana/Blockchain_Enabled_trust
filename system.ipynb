{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad049163",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "governance_overlay.py\n",
    "\n",
    "Reference implementation for:\n",
    "- Decentralized governance overlay (no raw medical data on-ledger)\n",
    "- Trust (hash commitments + provenance)\n",
    "- Audit (append-only ledger events)\n",
    "- Consent (machine-readable policy + enforcement checks)\n",
    "- Reproducibility (manifests to reconstruct decisions)\n",
    "- Optional decentralized compute concept for training/experiments on de-ID/synthetic\n",
    "\n",
    "This uses a local \"append-only hash-chained ledger\" to mimic blockchain properties.\n",
    "Swap LocalLedger with a real ledger client (Ratio1, Hyperledger, Ethereum, etc.) later.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ac3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time\n",
    "\n",
    "\n",
    "STAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "ARCHIVE_DIR = f\"results_{STAMP}\"\n",
    "\n",
    "os.makedirs(ARCHIVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cf09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import hashlib\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Utilities: stable hashing\n",
    "# -----------------------------\n",
    "\n",
    "def stable_json_dumps(obj: Any) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic JSON serialization.\n",
    "    \n",
    "    Ensures that the same object always produces the same JSON string,\n",
    "    regardless of Python's default dictionary ordering or execution environment.\n",
    "    This is critical for cryptographic hashing - two identical objects must\n",
    "    produce identical hashes.\n",
    "    \n",
    "    Args:\n",
    "        obj: Any JSON-serializable Python object\n",
    "        \n",
    "    Returns:\n",
    "        A deterministic JSON string with sorted keys and consistent separators\n",
    "    \"\"\"\n",
    "    return json.dumps(obj, sort_keys=True, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "\n",
    "\n",
    "def sha256_bytes(data: bytes) -> str:\n",
    "    \"\"\"\n",
    "    Compute SHA-256 hash of raw bytes.\n",
    "    \n",
    "    Args:\n",
    "        data: Raw bytes to hash\n",
    "        \n",
    "    Returns:\n",
    "        64-character hexadecimal hash string\n",
    "    \"\"\"\n",
    "    return hashlib.sha256(data).hexdigest()\n",
    "\n",
    "\n",
    "def sha256_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Compute SHA-256 hash of a text string.\n",
    "    \n",
    "    Args:\n",
    "        text: UTF-8 string to hash\n",
    "        \n",
    "    Returns:\n",
    "        64-character hexadecimal hash string\n",
    "    \"\"\"\n",
    "    return sha256_bytes(text.encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "def sha256_file(path: str, chunk_size: int = 1024 * 1024) -> str:\n",
    "    \"\"\"\n",
    "    Hash a file without loading it entirely into memory.\n",
    "    \n",
    "    This is essential for large medical images (DICOM, whole-slide imaging, etc.)\n",
    "    that may exceed available RAM. Reads file in chunks and incrementally\n",
    "    updates the hash.\n",
    "    \n",
    "    Args:\n",
    "        path: Filesystem path to the file\n",
    "        chunk_size: Number of bytes to read at once (default 1MB)\n",
    "        \n",
    "    Returns:\n",
    "        64-character hexadecimal SHA-256 hash of the entire file\n",
    "    \"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def now_epoch_ms() -> int:\n",
    "    \"\"\"\n",
    "    Get current Unix timestamp in milliseconds.\n",
    "    \n",
    "    Millisecond precision is useful for ordering events in high-frequency\n",
    "    audit logs where second-level timestamps might collide.\n",
    "    \n",
    "    Returns:\n",
    "        Current time as integer milliseconds since Unix epoch\n",
    "    \"\"\"\n",
    "    return int(time.time() * 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ae9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# 2) Consent policy model + enforcement\n",
    "# ---------------------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ConsentPolicy:\n",
    "    \"\"\"\n",
    "    A machine-readable consent policy representing patient authorization.\n",
    "    \n",
    "    In real-world clinical systems, this maps to:\n",
    "    - Legal consent forms signed by patients\n",
    "    - Institutional review board (IRB) approvals\n",
    "    - Data use agreements (DUAs)\n",
    "    - GDPR/HIPAA authorization documents\n",
    "    \n",
    "    The policy explicitly states:\n",
    "    - Who (roles) can access data\n",
    "    - For what purposes (clinical care vs research)\n",
    "    - Time validity window\n",
    "    - Whether consent can be revoked\n",
    "    \n",
    "    Attributes:\n",
    "        policy_id: Unique identifier for this consent policy\n",
    "        subject_id: Patient identifier (may be pseudonymous for privacy)\n",
    "        allowed_purposes: List of permitted data uses (e.g., [\"clinical_care\", \"research\"])\n",
    "        allowed_roles: List of authorized roles (e.g., [\"dermatologist\", \"ml_engineer\"])\n",
    "        valid_from_ms: Timestamp when consent becomes active (milliseconds)\n",
    "        valid_until_ms: Optional expiration timestamp; None means no expiry\n",
    "        revocable: Whether patient can withdraw consent later\n",
    "        revoked: Current revocation status\n",
    "        version: Policy version number (increments on updates)\n",
    "    \"\"\"\n",
    "    policy_id: str\n",
    "    subject_id: str\n",
    "    allowed_purposes: List[str]\n",
    "    allowed_roles: List[str]\n",
    "    valid_from_ms: int\n",
    "    valid_until_ms: Optional[int] = None\n",
    "    revocable: bool = True\n",
    "    revoked: bool = False\n",
    "    version: int = 1\n",
    "\n",
    "    def is_valid_at(self, t_ms: int) -> bool:\n",
    "        \"\"\"\n",
    "        Check if policy is temporally valid at a specific timestamp.\n",
    "        \n",
    "        A policy is valid if:\n",
    "        1. Current time is after valid_from_ms\n",
    "        2. Current time is before valid_until_ms (if set)\n",
    "        3. Policy has not been revoked\n",
    "        \n",
    "        Args:\n",
    "            t_ms: Timestamp to check (milliseconds since epoch)\n",
    "            \n",
    "        Returns:\n",
    "            True if policy is valid at the given time, False otherwise\n",
    "        \"\"\"\n",
    "        if t_ms < self.valid_from_ms:\n",
    "            return False\n",
    "        if self.valid_until_ms is not None and t_ms > self.valid_until_ms:\n",
    "            return False\n",
    "        if self.revoked:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def allows(self, purpose: str, role: str, t_ms: int) -> bool:\n",
    "        \"\"\"\n",
    "        Check if policy permits a specific access request.\n",
    "        \n",
    "        This is the core authorization check. Access is granted only if:\n",
    "        1. Policy is temporally valid\n",
    "        2. Requested purpose is in allowed_purposes\n",
    "        3. Requesting role is in allowed_roles\n",
    "        \n",
    "        Args:\n",
    "            purpose: Intended use of data (e.g., \"clinical_care\")\n",
    "            role: Role of requesting actor (e.g., \"dermatologist\")\n",
    "            t_ms: Timestamp of access request\n",
    "            \n",
    "        Returns:\n",
    "            True if access is authorized, False otherwise\n",
    "        \"\"\"\n",
    "        return self.is_valid_at(t_ms) and (purpose in self.allowed_purposes) and (role in self.allowed_roles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9842c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# 3) Manifests: preprocessing, training, inference, reproducibility\n",
    "# ---------------------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PipelineManifest:\n",
    "    \"\"\"\n",
    "    Describes the computational pipeline used to process data.\n",
    "    \n",
    "    This manifest captures the \"recipe\" for data processing, enabling:\n",
    "    - Reproducibility: Re-run exact same pipeline later\n",
    "    - Auditability: Know exactly what was done to the data\n",
    "    - Validation: Verify that approved pipelines were used\n",
    "    \n",
    "    In clinical AI, this might describe:\n",
    "    - Image preprocessing (normalization, resizing, augmentation)\n",
    "    - Inference pipelines (model + post-processing)\n",
    "    - Training workflows\n",
    "    \n",
    "    Attributes:\n",
    "        pipeline_name: Human-readable pipeline identifier\n",
    "        pipeline_version: Semantic version (e.g., \"1.2.0\")\n",
    "        container_image: Docker/OCI image reference for reproducibility\n",
    "        code_commit: Git commit hash linking to exact source code\n",
    "        parameters: Algorithm parameters (thresholds, sizes, etc.)\n",
    "        dependencies: Library versions (torch, numpy, etc.)\n",
    "    \"\"\"\n",
    "    pipeline_name: str\n",
    "    pipeline_version: str\n",
    "    container_image: Optional[str]\n",
    "    code_commit: Optional[str]\n",
    "    parameters: Dict[str, Any]\n",
    "    dependencies: Dict[str, str]\n",
    "\n",
    "    def fingerprint(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate cryptographic fingerprint of this pipeline configuration.\n",
    "        \n",
    "        Two pipelines with identical settings will produce identical fingerprints.\n",
    "        Any change to parameters, versions, or dependencies changes the fingerprint.\n",
    "        \n",
    "        Returns:\n",
    "            64-character hexadecimal SHA-256 hash\n",
    "        \"\"\"\n",
    "        return sha256_text(stable_json_dumps(asdict(self)))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelSpec:\n",
    "    \"\"\"\n",
    "    Identifies a specific AI/ML model version.\n",
    "    \n",
    "    Critical for clinical AI governance:\n",
    "    - Know which model version made each diagnosis\n",
    "    - Track model updates and retraining\n",
    "    - Link to validation/approval documentation\n",
    "    - Enable model rollback if issues found\n",
    "    \n",
    "    Attributes:\n",
    "        model_name: Model identifier (e.g., \"lesion_classifier\")\n",
    "        model_version: Version string (e.g., \"0.9.3\")\n",
    "        weights_hash: SHA-256 of model weights file (proves exact weights used)\n",
    "        framework: ML framework (pytorch, tensorflow, etc.)\n",
    "        extra: Additional metadata (calibration method, architecture notes, etc.)\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    model_version: str\n",
    "    weights_hash: Optional[str]\n",
    "    framework: str\n",
    "    extra: Dict[str, Any] = None\n",
    "\n",
    "    def fingerprint(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate cryptographic fingerprint of this model specification.\n",
    "        \n",
    "        Returns:\n",
    "            64-character hexadecimal SHA-256 hash\n",
    "        \"\"\"\n",
    "        return sha256_text(stable_json_dumps(asdict(self)))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ReproducibilityManifest:\n",
    "    \"\"\"\n",
    "    Complete \"receipt\" for reconstructing an AI decision.\n",
    "    \n",
    "    This is the gold standard for clinical AI reproducibility. It contains\n",
    "    everything needed to:\n",
    "    1. Verify what happened (audit)\n",
    "    2. Reproduce the exact same result (reproducibility)\n",
    "    3. Validate consent was obtained (compliance)\n",
    "    4. Trace back to original data (provenance)\n",
    "    \n",
    "    Key principle: Store hashes and pointers, NOT raw patient data.\n",
    "    Raw data stays in secure storage (PACS, EHR, cloud), only references\n",
    "    are recorded on-ledger.\n",
    "    \n",
    "    Attributes:\n",
    "        event_id: Unique identifier for this inference/processing event\n",
    "        created_at_ms: Timestamp of execution\n",
    "        input_artifact_hash: SHA-256 of input data (proves exact input used)\n",
    "        input_artifact_uri: Pointer to input data location (s3://, etc.)\n",
    "        output_artifact_hashes: SHA-256 hashes of all outputs\n",
    "        output_artifact_uris: Pointers to output locations\n",
    "        consent_policy_id: Which consent policy authorized this\n",
    "        consent_policy_hash: Hash of consent policy content (tamper detection)\n",
    "        pipeline_manifest_hash: Hash of pipeline that ran\n",
    "        model_spec_hash: Hash of model that was used\n",
    "        actor_id: Who ran this (user ID)\n",
    "        actor_role: Their role (dermatologist, engineer, etc.)\n",
    "        purpose: Why this ran (clinical_care, research, etc.)\n",
    "    \"\"\"\n",
    "    event_id: str\n",
    "    created_at_ms: int\n",
    "    input_artifact_hash: str\n",
    "    input_artifact_uri: str\n",
    "    output_artifact_hashes: Dict[str, str]\n",
    "    output_artifact_uris: Dict[str, str]\n",
    "    consent_policy_id: str\n",
    "    consent_policy_hash: str\n",
    "    pipeline_manifest_hash: str\n",
    "    model_spec_hash: str\n",
    "    actor_id: str\n",
    "    actor_role: str\n",
    "    purpose: str\n",
    "\n",
    "    def fingerprint(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate cryptographic fingerprint of this reproducibility manifest.\n",
    "        \n",
    "        Returns:\n",
    "            64-character hexadecimal SHA-256 hash\n",
    "        \"\"\"\n",
    "        return sha256_text(stable_json_dumps(asdict(self)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f0a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# 4) Ledger: append-only, hash-chained\n",
    "# ---------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class LedgerEntry:\n",
    "    \"\"\"\n",
    "    A single immutable entry in the governance ledger.\n",
    "    \n",
    "    Each entry is a \"block\" containing:\n",
    "    - Event metadata (type, timestamp, ID)\n",
    "    - Event payload (hashes, decisions, audit data - NO PHI)\n",
    "    - Hash chain links (prev_hash, entry_hash)\n",
    "    \n",
    "    The hash chain ensures tamper-evidence: changing any entry\n",
    "    breaks all subsequent entries' hashes.\n",
    "    \n",
    "    Attributes:\n",
    "        entry_id: Unique UUID for this entry\n",
    "        timestamp_ms: When entry was created\n",
    "        event_type: Category of event (e.g., \"CONSENT_CREATED\", \"INFERENCE_EXECUTED\")\n",
    "        payload: Event-specific data (must not contain raw PHI)\n",
    "        prev_hash: Hash of previous entry (creates chain)\n",
    "        entry_hash: Hash of this entry (computed from prev_hash + content)\n",
    "    \"\"\"\n",
    "    entry_id: str\n",
    "    timestamp_ms: int\n",
    "    event_type: str\n",
    "    payload: Dict[str, Any]\n",
    "    prev_hash: str\n",
    "    entry_hash: str\n",
    "\n",
    "\n",
    "class LocalLedger:\n",
    "    \"\"\"\n",
    "    Append-only ledger with cryptographic hash chaining.\n",
    "    \n",
    "    This is a local implementation mimicking blockchain properties:\n",
    "    1. Append-only: Can only add entries, never modify/delete\n",
    "    2. Hash-chained: Each entry links to previous via cryptographic hash\n",
    "    3. Tamper-evident: Any modification breaks chain integrity\n",
    "    4. Auditable: Complete history of all governance events\n",
    "    \n",
    "    In production, replace with:\n",
    "    - Private blockchain (Hyperledger Fabric)\n",
    "    - Public blockchain (Ethereum, with privacy layers)\n",
    "    - Distributed ledger (Ratio1, Corda)\n",
    "    - Centralized but signed audit log (AWS QLDB)\n",
    "    \n",
    "    Storage format: JSON Lines (one JSON object per line)\n",
    "    Each line is a complete LedgerEntry that can be parsed independently.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ledger_path: str):\n",
    "        \"\"\"\n",
    "        Initialize or open existing ledger.\n",
    "        \n",
    "        If ledger doesn't exist, creates it with a genesis entry.\n",
    "        Genesis is the first entry with prev_hash = \"0\" * 64.\n",
    "        \n",
    "        Args:\n",
    "            ledger_path: Filesystem path to ledger file\n",
    "        \"\"\"\n",
    "        self.ledger_path = ledger_path\n",
    "        os.makedirs(os.path.dirname(ledger_path) or \".\", exist_ok=True)\n",
    "        if not os.path.exists(ledger_path):\n",
    "            # Genesis entry: first entry in chain\n",
    "            self._write_raw({\"genesis\": True, \"created_at_ms\": now_epoch_ms()})\n",
    "\n",
    "    def _read_all_raw(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Read all entries from ledger file.\n",
    "        \n",
    "        Returns:\n",
    "            List of dictionaries, one per ledger entry\n",
    "        \"\"\"\n",
    "        with open(self.ledger_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "    def _write_raw(self, obj: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Append a raw JSON object to ledger file.\n",
    "        \n",
    "        Uses append mode to prevent overwriting existing entries.\n",
    "        Each object is written on its own line (JSON Lines format).\n",
    "        \n",
    "        Args:\n",
    "            obj: Dictionary to serialize and append\n",
    "        \"\"\"\n",
    "        with open(self.ledger_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def last_hash(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the hash of the most recent ledger entry.\n",
    "        \n",
    "        This is needed to compute the next entry's prev_hash,\n",
    "        which creates the hash chain linking.\n",
    "        \n",
    "        Returns:\n",
    "            Hash of last entry, or \"0\"*64 if ledger only has genesis\n",
    "        \"\"\"\n",
    "        rows = self._read_all_raw()\n",
    "        # Find last actual LedgerEntry; genesis line has no entry_hash\n",
    "        for row in reversed(rows):\n",
    "            if \"entry_hash\" in row:\n",
    "                return row[\"entry_hash\"]\n",
    "        return \"0\" * 64\n",
    "\n",
    "    def append(self, event_type: str, payload: Dict[str, Any]) -> LedgerEntry:\n",
    "        \"\"\"\n",
    "        Append a new governance event to the ledger.\n",
    "        \n",
    "        Process:\n",
    "        1. Get previous entry's hash\n",
    "        2. Create entry with prev_hash link\n",
    "        3. Compute entry_hash = SHA256(prev_hash + entry_content)\n",
    "        4. Write to disk (append-only)\n",
    "        \n",
    "        The hash computation is deterministic and tamper-evident:\n",
    "        - Changing payload breaks entry_hash\n",
    "        - Changing prev_hash breaks chain\n",
    "        - Deleting/reordering entries breaks chain\n",
    "        \n",
    "        Args:\n",
    "            event_type: Category of event (e.g., \"CONSENT_CREATED\")\n",
    "            payload: Event-specific data (NO PHI - only hashes/pointers)\n",
    "            \n",
    "        Returns:\n",
    "            Complete LedgerEntry object with computed hashes\n",
    "        \"\"\"\n",
    "        prev = self.last_hash()\n",
    "        entry_id = str(uuid.uuid4())\n",
    "        ts = now_epoch_ms()\n",
    "\n",
    "        # Body contains all fields except entry_hash\n",
    "        body = {\n",
    "            \"entry_id\": entry_id,\n",
    "            \"timestamp_ms\": ts,\n",
    "            \"event_type\": event_type,\n",
    "            \"payload\": payload,\n",
    "            \"prev_hash\": prev,\n",
    "        }\n",
    "        # Hash is computed from prev_hash + body\n",
    "        entry_hash = sha256_text(prev + stable_json_dumps(body))\n",
    "        entry = LedgerEntry(\n",
    "            entry_id=entry_id,\n",
    "            timestamp_ms=ts,\n",
    "            event_type=event_type,\n",
    "            payload=payload,\n",
    "            prev_hash=prev,\n",
    "            entry_hash=entry_hash\n",
    "        )\n",
    "\n",
    "        self._write_raw(asdict(entry))\n",
    "        return entry\n",
    "\n",
    "    def verify_integrity(self) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Verify cryptographic integrity of entire ledger.\n",
    "        \n",
    "        Walks through every entry and verifies:\n",
    "        1. prev_hash matches previous entry's entry_hash\n",
    "        2. entry_hash is correctly computed from prev_hash + content\n",
    "        \n",
    "        If ANY entry is tampered with, verification fails.\n",
    "        This is how we detect unauthorized modifications.\n",
    "        \n",
    "        Returns:\n",
    "            (success: bool, error_message: Optional[str])\n",
    "            - (True, None) if ledger is intact\n",
    "            - (False, \"error description\") if tampering detected\n",
    "        \"\"\"\n",
    "        rows = self._read_all_raw()\n",
    "        prev = \"0\" * 64\n",
    "\n",
    "        for row in rows:\n",
    "            if row.get(\"genesis\"):\n",
    "                continue\n",
    "            expected_body = {\n",
    "                \"entry_id\": row[\"entry_id\"],\n",
    "                \"timestamp_ms\": row[\"timestamp_ms\"],\n",
    "                \"event_type\": row[\"event_type\"],\n",
    "                \"payload\": row[\"payload\"],\n",
    "                \"prev_hash\": row[\"prev_hash\"],\n",
    "            }\n",
    "            expected_hash = sha256_text(prev + stable_json_dumps(expected_body))\n",
    "            if row[\"prev_hash\"] != prev:\n",
    "                return False, f\"Broken prev_hash link at entry {row['entry_id']}\"\n",
    "            if row[\"entry_hash\"] != expected_hash:\n",
    "                return False, f\"Hash mismatch at entry {row['entry_id']}\"\n",
    "            prev = row[\"entry_hash\"]\n",
    "\n",
    "        return True, None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556d7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# 5) Governance Overlay Orchestrator\n",
    "# ---------------------------------------\n",
    "\n",
    "class GovernanceOverlay:\n",
    "    \"\"\"\n",
    "    High-level API orchestrating consent, audit, and reproducibility.\n",
    "    \n",
    "    This is the main interface for clinical AI governance. It provides:\n",
    "    1. Consent management (store, verify, revoke policies)\n",
    "    2. Access auditing (log all data access events)\n",
    "    3. Inference recording (create reproducibility manifests)\n",
    "    4. Training logging (record model training experiments)\n",
    "    \n",
    "    Architecture:\n",
    "    - Sensitive data (consent policies, manifests) stored OFF-ledger\n",
    "    - Only hashes and pointers stored ON-ledger\n",
    "    - Ledger is tamper-evident but doesn't contain PHI\n",
    "    \n",
    "    This separation is crucial for:\n",
    "    - Privacy: PHI never on distributed ledger\n",
    "    - Scalability: Large files don't bloat ledger\n",
    "    - Flexibility: Can change storage without touching ledger\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ledger: LocalLedger, policy_store_dir: str = f\"{ARCHIVE_DIR}/policy_store\", manifest_store_dir: str = f\"{ARCHIVE_DIR}/manifest_store\"):\n",
    "        \"\"\"\n",
    "        Initialize governance system.\n",
    "        \n",
    "        Args:\n",
    "            ledger: Append-only ledger for immutable audit trail\n",
    "            policy_store_dir: Directory for off-ledger consent policies\n",
    "            manifest_store_dir: Directory for off-ledger manifests\n",
    "        \"\"\"\n",
    "        self.ledger = ledger\n",
    "        self.policy_store_dir = policy_store_dir\n",
    "        self.manifest_store_dir = manifest_store_dir\n",
    "        os.makedirs(policy_store_dir, exist_ok=True)\n",
    "        os.makedirs(manifest_store_dir, exist_ok=True)\n",
    "\n",
    "    # ---------- Consent handling ----------\n",
    "\n",
    "    def _policy_path(self, policy_id: str) -> str:\n",
    "        \"\"\"Get filesystem path for a consent policy file.\"\"\"\n",
    "        return os.path.join(self.policy_store_dir, f\"{policy_id}.json\")\n",
    "\n",
    "    def store_consent_policy(self, policy: ConsentPolicy) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Store a consent policy and record its hash on-ledger.\n",
    "        \n",
    "        Two-tier storage:\n",
    "        1. OFF-ledger: Full policy JSON in local file (may contain pseudonymous IDs)\n",
    "        2. ON-ledger: Only policy hash + metadata (no direct PHI)\n",
    "        \n",
    "        This enables:\n",
    "        - Privacy: Patient data not on public/distributed ledger\n",
    "        - Verification: Can prove policy hasn't been tampered with\n",
    "        - Audit: Immutable record of consent creation\n",
    "        \n",
    "        Args:\n",
    "            policy: ConsentPolicy object to store\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with policy_id and policy_hash\n",
    "        \"\"\"\n",
    "        policy_dict = asdict(policy)\n",
    "        policy_json = stable_json_dumps(policy_dict)\n",
    "        policy_hash = sha256_text(policy_json)\n",
    "\n",
    "        # Off-ledger store (secure local/cloud storage)\n",
    "        with open(self._policy_path(policy.policy_id), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(policy_json)\n",
    "\n",
    "        # On-ledger record (only hash + non-PHI metadata)\n",
    "        self.ledger.append(\n",
    "            event_type=\"CONSENT_CREATED\",\n",
    "            payload={\n",
    "                \"policy_id\": policy.policy_id,\n",
    "                \"policy_hash\": policy_hash,\n",
    "                \"subject_id\": policy.subject_id,  # May be pseudonymous\n",
    "                \"version\": policy.version,\n",
    "                \"valid_from_ms\": policy.valid_from_ms,\n",
    "                \"valid_until_ms\": policy.valid_until_ms,\n",
    "                \"revocable\": policy.revocable,\n",
    "            }\n",
    "        )\n",
    "        return {\"policy_id\": policy.policy_id, \"policy_hash\": policy_hash}\n",
    "\n",
    "    def revoke_consent_policy(self, policy_id: str, actor_id: str) -> None:\n",
    "        \"\"\"\n",
    "        Revoke a consent policy (patient withdraws authorization).\n",
    "        \n",
    "        Process:\n",
    "        1. Load existing policy\n",
    "        2. Check if revocable\n",
    "        3. Mark as revoked and increment version\n",
    "        4. Save updated policy off-ledger\n",
    "        5. Record revocation event on-ledger\n",
    "        \n",
    "        After revocation, future access checks will fail.\n",
    "        \n",
    "        Args:\n",
    "            policy_id: ID of policy to revoke\n",
    "            actor_id: Who requested revocation (patient, admin, etc.)\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If policy doesn't exist\n",
    "            ValueError: If policy is not revocable\n",
    "        \"\"\"\n",
    "        path = self._policy_path(policy_id)\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Unknown policy_id: {policy_id}\")\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            d = json.loads(f.read())\n",
    "\n",
    "        if not d.get(\"revocable\", True):\n",
    "            raise ValueError(\"Policy is not revocable\")\n",
    "\n",
    "        d[\"revoked\"] = True\n",
    "        d[\"version\"] = int(d.get(\"version\", 1)) + 1\n",
    "\n",
    "        policy_json = stable_json_dumps(d)\n",
    "        new_hash = sha256_text(policy_json)\n",
    "\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(policy_json)\n",
    "\n",
    "        self.ledger.append(\n",
    "            event_type=\"CONSENT_REVOKED\",\n",
    "            payload={\"policy_id\": policy_id, \"new_policy_hash\": new_hash, \"actor_id\": actor_id}\n",
    "        )\n",
    "\n",
    "    def load_consent_policy(self, policy_id: str) -> ConsentPolicy:\n",
    "        \"\"\"\n",
    "        Load a consent policy from off-ledger storage.\n",
    "        \n",
    "        Args:\n",
    "            policy_id: ID of policy to load\n",
    "            \n",
    "        Returns:\n",
    "            ConsentPolicy object\n",
    "        \"\"\"\n",
    "        path = self._policy_path(policy_id)\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            d = json.loads(f.read())\n",
    "        return ConsentPolicy(**d)\n",
    "\n",
    "    def check_consent(self, policy_id: str, purpose: str, actor_role: str, t_ms: Optional[int] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Check if consent policy permits a specific access request.\n",
    "        \n",
    "        This is the authorization gateway. Before any data access,\n",
    "        this function verifies:\n",
    "        1. Policy exists\n",
    "        2. Policy is temporally valid\n",
    "        3. Purpose is authorized\n",
    "        4. Role is authorized\n",
    "        \n",
    "        Args:\n",
    "            policy_id: Which consent policy to check\n",
    "            purpose: Intended use (e.g., \"clinical_care\")\n",
    "            actor_role: Requesting role (e.g., \"dermatologist\")\n",
    "            t_ms: Check at this timestamp (default: now)\n",
    "            \n",
    "        Returns:\n",
    "            True if access authorized, False otherwise\n",
    "        \"\"\"\n",
    "        t_ms = now_epoch_ms() if t_ms is None else t_ms\n",
    "        policy = self.load_consent_policy(policy_id)\n",
    "        return policy.allows(purpose=purpose, role=actor_role, t_ms=t_ms)\n",
    "\n",
    "    # ---------- Manifests ----------\n",
    "\n",
    "    def _manifest_path(self, manifest_id: str) -> str:\n",
    "        \"\"\"Get filesystem path for a manifest file.\"\"\"\n",
    "        return os.path.join(self.manifest_store_dir, f\"{manifest_id}.json\")\n",
    "\n",
    "    def store_manifest_off_ledger(self, manifest: Any, manifest_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Store any manifest off-ledger and return its hash.\n",
    "        \n",
    "        Manifests (pipeline configs, reproducibility receipts) are stored\n",
    "        off-ledger because they can be large. Only their hashes go on-ledger.\n",
    "        \n",
    "        Args:\n",
    "            manifest: Manifest object (must have asdict() method)\n",
    "            manifest_id: Unique identifier for this manifest\n",
    "            \n",
    "        Returns:\n",
    "            SHA-256 hash of manifest content\n",
    "        \"\"\"\n",
    "        manifest_json = stable_json_dumps(asdict(manifest))\n",
    "        manifest_hash = sha256_text(manifest_json)\n",
    "        with open(self._manifest_path(manifest_id), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(manifest_json)\n",
    "        return manifest_hash\n",
    "\n",
    "    # ---------- Audit / provenance ----------\n",
    "\n",
    "    def record_data_access(self, actor_id: str, actor_role: str, purpose: str, artifact_uri: str, artifact_hash: str) -> None:\n",
    "        \"\"\"\n",
    "        Log a data access event to the audit ledger.\n",
    "        \n",
    "        Creates immutable record of:\n",
    "        - Who accessed data\n",
    "        - Their role and purpose\n",
    "        - What data was accessed (via URI + hash)\n",
    "        - When access occurred\n",
    "        \n",
    "        This supports:\n",
    "        - Audit trails for compliance (HIPAA, GDPR)\n",
    "        - Breach investigation (who accessed what when)\n",
    "        - Usage analytics (how often is data accessed)\n",
    "        \n",
    "        Args:\n",
    "            actor_id: User/system identifier\n",
    "            actor_role: Their role (dermatologist, engineer, etc.)\n",
    "            purpose: Why they accessed (clinical_care, research, etc.)\n",
    "            artifact_uri: Pointer to data (s3://, file://, etc.)\n",
    "            artifact_hash: SHA-256 of data (proves exact version accessed)\n",
    "        \"\"\"\n",
    "        self.ledger.append(\n",
    "            event_type=\"DATA_ACCESSED\",\n",
    "            payload={\n",
    "                \"actor_id\": actor_id,\n",
    "                \"actor_role\": actor_role,\n",
    "                \"purpose\": purpose,\n",
    "                \"artifact_uri\": artifact_uri,\n",
    "                \"artifact_hash\": artifact_hash,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # ---------- Inference \"receipt\" ----------\n",
    "\n",
    "    def record_inference(\n",
    "        self,\n",
    "        actor_id: str,\n",
    "        actor_role: str,\n",
    "        purpose: str,\n",
    "        consent_policy_id: str,\n",
    "        input_artifact_uri: str,\n",
    "        input_artifact_hash: str,\n",
    "        output_artifacts: Dict[str, Tuple[str, str]],\n",
    "        pipeline_manifest: PipelineManifest,\n",
    "        model_spec: ModelSpec,\n",
    "    ) -> ReproducibilityManifest:\n",
    "        \"\"\"\n",
    "        Record an AI inference run with full reproducibility.\n",
    "        \n",
    "        This is the core function for clinical AI governance. It creates\n",
    "        a complete audit trail for each AI decision:\n",
    "        \n",
    "        1. Consent check: Verify authorization before processing\n",
    "        2. Manifest creation: Document exactly what ran (model, pipeline, params)\n",
    "        3. Ledger recording: Write immutable audit event\n",
    "        4. Reproducibility: Enable exact reconstruction of decision later\n",
    "        \n",
    "        If consent check fails, logs CONSENT_DENIED event and raises error.\n",
    "        \n",
    "        Process flow:\n",
    "        1. Check consent authorization\n",
    "        2. Hash consent policy content\n",
    "        3. Compute pipeline + model fingerprints\n",
    "        4. Create reproducibility manifest with all references\n",
    "        5. Store manifest off-ledger\n",
    "        6. Write INFERENCE_EXECUTED event on-ledger (hashes only)\n",
    "        \n",
    "        Args:\n",
    "            actor_id: Who ran inference (user ID)\n",
    "            actor_role: Their role (dermatologist, ml_engineer, etc.)\n",
    "            purpose: Why inference ran (clinical_care, research, etc.)\n",
    "            consent_policy_id: Which consent authorizes this\n",
    "            input_artifact_uri: Pointer to input data (s3://, etc.)\n",
    "            input_artifact_hash: SHA-256 of input (proves exact input)\n",
    "            output_artifacts: Dict mapping output names to (uri, hash) tuples\n",
    "            pipeline_manifest: Description of processing pipeline\n",
    "            model_spec: Description of AI model used\n",
    "            \n",
    "        Returns:\n",
    "            ReproducibilityManifest containing all information needed\n",
    "            to reconstruct this inference later\n",
    "            \n",
    "        Raises:\n",
    "            PermissionError: If consent check fails\n",
    "        \"\"\"\n",
    "        t_ms = now_epoch_ms()\n",
    "\n",
    "        # Authorization check BEFORE processing\n",
    "        if not self.check_consent(consent_policy_id, purpose, actor_role, t_ms=t_ms):\n",
    "            # Log denial for audit trail\n",
    "            self.ledger.append(\n",
    "                event_type=\"CONSENT_DENIED\",\n",
    "                payload={\n",
    "                    \"policy_id\": consent_policy_id,\n",
    "                    \"actor_id\": actor_id,\n",
    "                    \"actor_role\": actor_role,\n",
    "                    \"purpose\": purpose,\n",
    "                    \"timestamp_ms\": t_ms,\n",
    "                }\n",
    "            )\n",
    "            raise PermissionError(\"Consent check failed\")\n",
    "\n",
    "        # Hash consent policy content (for tamper detection)\n",
    "        policy = self.load_consent_policy(consent_policy_id)\n",
    "        policy_hash = sha256_text(stable_json_dumps(asdict(policy)))\n",
    "\n",
    "        # Store pipeline + model manifests off-ledger and get fingerprints\n",
    "        pipeline_hash = pipeline_manifest.fingerprint()\n",
    "        model_hash = model_spec.fingerprint()\n",
    "\n",
    "        # Prepare output mapping\n",
    "        out_uris = {k: v[0] for k, v in output_artifacts.items()}\n",
    "        out_hashes = {k: v[1] for k, v in output_artifacts.items()}\n",
    "\n",
    "        # Create reproducibility manifest\n",
    "        event_id = str(uuid.uuid4())\n",
    "        repro = ReproducibilityManifest(\n",
    "            event_id=event_id,\n",
    "            created_at_ms=t_ms,\n",
    "            input_artifact_hash=input_artifact_hash,\n",
    "            input_artifact_uri=input_artifact_uri,\n",
    "            output_artifact_hashes=out_hashes,\n",
    "            output_artifact_uris=out_uris,\n",
    "            consent_policy_id=consent_policy_id,\n",
    "            consent_policy_hash=policy_hash,\n",
    "            pipeline_manifest_hash=pipeline_hash,\n",
    "            model_spec_hash=model_hash,\n",
    "            actor_id=actor_id,\n",
    "            actor_role=actor_role,\n",
    "            purpose=purpose\n",
    "        )\n",
    "\n",
    "        # Store full reproducibility manifest off-ledger\n",
    "        repro_hash = self.store_manifest_off_ledger(repro, manifest_id=f\"repro_{event_id}\")\n",
    "\n",
    "        # Write ledger event (only references + hashes, NO PHI)\n",
    "        self.ledger.append(\n",
    "            event_type=\"INFERENCE_EXECUTED\",\n",
    "            payload={\n",
    "                \"event_id\": event_id,\n",
    "                \"actor_id\": actor_id,\n",
    "                \"actor_role\": actor_role,\n",
    "                \"purpose\": purpose,\n",
    "                \"consent_policy_id\": consent_policy_id,\n",
    "                \"consent_policy_hash\": policy_hash,\n",
    "                \"input_artifact_uri\": input_artifact_uri,\n",
    "                \"input_artifact_hash\": input_artifact_hash,\n",
    "                \"output_artifact_uris\": out_uris,\n",
    "                \"output_artifact_hashes\": out_hashes,\n",
    "                \"pipeline_manifest_hash\": pipeline_hash,\n",
    "                \"model_spec_hash\": model_hash,\n",
    "                \"repro_manifest_hash\": repro_hash,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return repro\n",
    "\n",
    "    # ---------- Training / experiments on de-ID or synthetic data ----------\n",
    "\n",
    "    def record_training_experiment(\n",
    "        self,\n",
    "        actor_id: str,\n",
    "        actor_role: str,\n",
    "        purpose: str,\n",
    "        dataset_uri: str,\n",
    "        dataset_hash: str,\n",
    "        dataset_type: str,\n",
    "        training_manifest: PipelineManifest,\n",
    "        model_spec_before: ModelSpec,\n",
    "        model_spec_after: ModelSpec,\n",
    "        compute_backend: str,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Log a model training/experiment run.\n",
    "        \n",
    "        For research/development, training typically uses:\n",
    "        - De-identified data (PHI removed/pseudonymized)\n",
    "        - Synthetic data (generated, no real patients)\n",
    "        - Decentralized compute (privacy-preserving training)\n",
    "        \n",
    "        This function records:\n",
    "        - What dataset was used (must be de-ID or synthetic)\n",
    "        - Training configuration (hyperparameters, etc.)\n",
    "        - Model before and after training\n",
    "        - Where training ran (local, cloud, federated, etc.)\n",
    "        \n",
    "        Creates immutable audit trail of all model development.\n",
    "        \n",
    "        Args:\n",
    "            actor_id: Who ran training\n",
    "            actor_role: Their role (ml_engineer, researcher, etc.)\n",
    "            purpose: Why training ran (usually \"research\")\n",
    "            dataset_uri: Pointer to training dataset\n",
    "            dataset_hash: SHA-256 of dataset\n",
    "            dataset_type: Must be \"deidentified\" or \"synthetic\"\n",
    "            training_manifest: Training pipeline configuration\n",
    "            model_spec_before: Model version before training\n",
    "            model_spec_after: Model version after training\n",
    "            compute_backend: Where training ran (\"ratio1\", \"aws\", \"local\", etc.)\n",
    "            \n",
    "        Returns:\n",
    "            Event ID (UUID) of training record\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If dataset_type is not \"deidentified\" or \"synthetic\"\n",
    "        \"\"\"\n",
    "        if dataset_type not in {\"deidentified\", \"synthetic\"}:\n",
    "            raise ValueError(\"dataset_type must be 'deidentified' or 'synthetic'\")\n",
    "\n",
    "        t_ms = now_epoch_ms()\n",
    "        event_id = str(uuid.uuid4())\n",
    "\n",
    "        train_hash = training_manifest.fingerprint()\n",
    "        model_before_hash = model_spec_before.fingerprint()\n",
    "        model_after_hash = model_spec_after.fingerprint()\n",
    "\n",
    "        payload = {\n",
    "            \"event_id\": event_id,\n",
    "            \"timestamp_ms\": t_ms,\n",
    "            \"actor_id\": actor_id,\n",
    "            \"actor_role\": actor_role,\n",
    "            \"purpose\": purpose,\n",
    "            \"dataset_uri\": dataset_uri,\n",
    "            \"dataset_hash\": dataset_hash,\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"training_manifest_hash\": train_hash,\n",
    "            \"model_before_hash\": model_before_hash,\n",
    "            \"model_after_hash\": model_after_hash,\n",
    "            \"compute_backend\": compute_backend,\n",
    "        }\n",
    "\n",
    "        self.ledger.append(event_type=\"TRAINING_EXPERIMENT_EXECUTED\", payload=payload)\n",
    "        return event_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42aa7e9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ðŸŽ¯ Priority Recommendations\n",
    "\n",
    "For **immediate impact**, I'd suggest implementing:\n",
    "\n",
    "1. **Zero-Knowledge Proofs** (#1) - Cutting edge for privacy\n",
    "2. **Differential Privacy** (#2) - Industry standard for medical AI\n",
    "3. **Federated Learning** (#3) - Hot topic in multi-institutional research\n",
    "4. **Explainability Provenance** (#10) - Critical for clinical acceptance\n",
    "\n",
    "These would make your system truly state-of-the-art for 2025 clinical AI governance!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9549680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# 6) Example usage (run this as a script)\n",
    "# ---------------------------------------\n",
    "\n",
    "def demo():\n",
    "    \"\"\"\n",
    "    Demonstration of complete governance workflow.\n",
    "    \n",
    "    Shows end-to-end example:\n",
    "    1. Create ledger + governance system\n",
    "    2. Store consent policy\n",
    "    3. Record data access\n",
    "    4. Run AI inference with full reproducibility\n",
    "    5. Record model training experiment\n",
    "    6. Verify ledger integrity\n",
    "    \n",
    "    This is a reference implementation showing how all pieces fit together.\n",
    "    \"\"\"\n",
    "\n",
    "    ledger = LocalLedger(f\"{ARCHIVE_DIR}/ledger/clinical_governance_ledger.jsonl\")\n",
    "    overlay = GovernanceOverlay(ledger)\n",
    "\n",
    "    # --- Consent: create policy ---\n",
    "    policy = ConsentPolicy(\n",
    "        policy_id=\"consent_001\",\n",
    "        subject_id=\"patient_pseudo_123\",  # pseudonymous\n",
    "        allowed_purposes=[\"clinical_care\", \"research\"],\n",
    "        allowed_roles=[\"dermatologist\", \"ml_engineer\"],\n",
    "        valid_from_ms=now_epoch_ms() - 1000,\n",
    "        valid_until_ms=None,\n",
    "        revocable=True,\n",
    "        revoked=False,\n",
    "        version=1\n",
    "    )\n",
    "    overlay.store_consent_policy(policy)\n",
    "\n",
    "    # --- Input artifact (pretend an image exists in cloud) ---\n",
    "    # In real system: image stored in S3/Azure/GCP. Here: local file hash as example.\n",
    "    # If you don't have a real image, create a dummy file.\n",
    "    dummy_img_path = f\"{ARCHIVE_DIR}/data/example_image.bin\"\n",
    "    os.makedirs(f\"{ARCHIVE_DIR}/data\", exist_ok=True)\n",
    "    if not os.path.exists(dummy_img_path):\n",
    "        with open(dummy_img_path, \"wb\") as f:\n",
    "            f.write(os.urandom(4096))  # dummy bytes\n",
    "\n",
    "    input_hash = sha256_file(dummy_img_path)\n",
    "    input_uri = \"s3://noetiv-bucket/patient_pseudo_123/visit1/image1.jpg\"  # example pointer\n",
    "\n",
    "    overlay.record_data_access(\n",
    "        actor_id=\"user_42\",\n",
    "        actor_role=\"dermatologist\",\n",
    "        purpose=\"clinical_care\",\n",
    "        artifact_uri=input_uri,\n",
    "        artifact_hash=input_hash\n",
    "    )\n",
    "\n",
    "    # --- Pipeline + model specs (what ran) ---\n",
    "    pipeline = PipelineManifest(\n",
    "        pipeline_name=\"dermoscopy_inference\",\n",
    "        pipeline_version=\"1.0.0\",\n",
    "        container_image=\"registry/noetiv/dermoscopy:1.0.0\",\n",
    "        code_commit=\"abc123def\",\n",
    "        parameters={\"img_size\": 512, \"threshold\": 0.35, \"xai\": True},\n",
    "        dependencies={\"python\": \"3.11\", \"torch\": \"2.4.0\", \"numpy\": \"2.0.1\"}\n",
    "    )\n",
    "\n",
    "    model = ModelSpec(\n",
    "        model_name=\"lesion_classifier\",\n",
    "        model_version=\"0.9.3\",\n",
    "        weights_hash=\"deadbeef...\" ,  # replace with real hash/digest\n",
    "        framework=\"pytorch\",\n",
    "        extra={\"calibration\": \"temperature_scaling_v2\"}\n",
    "    )\n",
    "\n",
    "    # --- Output artifacts (pretend saved in cloud) ---\n",
    "    # In practice, these are report JSON, mask PNG, heatmap, etc.\n",
    "    # Here we generate dummy bytes and hash them.\n",
    "    report_path = f\"{ARCHIVE_DIR}/data/report.json\"\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(stable_json_dumps({\"prediction\": \"benign\", \"confidence\": 0.83}))\n",
    "\n",
    "    report_hash = sha256_file(report_path)\n",
    "    report_uri = \"s3://noetiv-bucket/patient_pseudo_123/visit1/report.json\"\n",
    "\n",
    "    outputs = {\n",
    "        \"report_json\": (report_uri, report_hash),\n",
    "    }\n",
    "\n",
    "    # --- Record inference with reproducibility manifest ---\n",
    "    repro = overlay.record_inference(\n",
    "        actor_id=\"user_42\",\n",
    "        actor_role=\"dermatologist\",\n",
    "        purpose=\"clinical_care\",\n",
    "        consent_policy_id=\"consent_001\",\n",
    "        input_artifact_uri=input_uri,\n",
    "        input_artifact_hash=input_hash,\n",
    "        output_artifacts=outputs,\n",
    "        pipeline_manifest=pipeline,\n",
    "        model_spec=model,\n",
    "    )\n",
    "\n",
    "    print(\"Reproducibility manifest created:\")\n",
    "    print(stable_json_dumps(asdict(repro)))\n",
    "\n",
    "    # --- Record a training experiment (de-ID or synthetic) on \"decentralized compute\" ---\n",
    "    train_pipeline = PipelineManifest(\n",
    "        pipeline_name=\"train_lesion_classifier\",\n",
    "        pipeline_version=\"0.1.0\",\n",
    "        container_image=\"registry/noetiv/train:0.1.0\",\n",
    "        code_commit=\"train789\",\n",
    "        parameters={\"epochs\": 10, \"lr\": 1e-4, \"batch_size\": 16},\n",
    "        dependencies={\"python\": \"3.11\", \"torch\": \"2.4.0\"}\n",
    "    )\n",
    "\n",
    "    model_before = model\n",
    "    model_after = ModelSpec(\n",
    "        model_name=\"lesion_classifier\",\n",
    "        model_version=\"0.9.4\",\n",
    "        weights_hash=\"feedface...\",  # replace with real hash/digest\n",
    "        framework=\"pytorch\",\n",
    "        extra={\"notes\": \"trained on synthetic dataset v2\"}\n",
    "    )\n",
    "\n",
    "    # Example: synthetic dataset pointer + hash\n",
    "    synthetic_dataset_path = f\"{ARCHIVE_DIR}/data/synth_dataset.bin\"\n",
    "    with open(synthetic_dataset_path, \"wb\") as f:\n",
    "        f.write(os.urandom(8192))\n",
    "\n",
    "    dataset_hash = sha256_file(synthetic_dataset_path)\n",
    "    dataset_uri = \"s3://noetiv-research/synthetic/derm_v2/dataset.tar\"\n",
    "\n",
    "    training_event_id = overlay.record_training_experiment(\n",
    "        actor_id=\"user_99\",\n",
    "        actor_role=\"ml_engineer\",\n",
    "        purpose=\"research\",\n",
    "        dataset_uri=dataset_uri,\n",
    "        dataset_hash=dataset_hash,\n",
    "        dataset_type=\"synthetic\",\n",
    "        training_manifest=train_pipeline,\n",
    "        model_spec_before=model_before,\n",
    "        model_spec_after=model_after,\n",
    "        compute_backend=\"ratio1\"  # conceptually\n",
    "    )\n",
    "\n",
    "    print(\"Training experiment recorded:\", training_event_id)\n",
    "\n",
    "    # --- Verify ledger integrity (auditor step) ---\n",
    "    ok, err = ledger.verify_integrity()\n",
    "    print(\"Ledger integrity OK?\" , ok, err)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6586c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproducibility manifest created:\n",
      "{\"actor_id\":\"user_42\",\"actor_role\":\"dermatologist\",\"consent_policy_hash\":\"51df09aee42907709f55997615e18e9690d5a2374007aad880fad8b970db0c26\",\"consent_policy_id\":\"consent_001\",\"created_at_ms\":1766177554112,\"event_id\":\"8e70bd7a-fee2-435c-9527-2cf6103bb5f4\",\"input_artifact_hash\":\"800cb786fe3d72734d24e848df4894ff6b626687ad147b55a95d12df3a10d837\",\"input_artifact_uri\":\"s3://noetiv-bucket/patient_pseudo_123/visit1/image1.jpg\",\"model_spec_hash\":\"0cdab167e8a42f210da84c0963f80928624db9cce89a7c026aa081806a3ee427\",\"output_artifact_hashes\":{\"report_json\":\"99e6f5f9bbe470bb28bc864fa9de01f08f070dc8841536aa579e4b98599a7dc5\"},\"output_artifact_uris\":{\"report_json\":\"s3://noetiv-bucket/patient_pseudo_123/visit1/report.json\"},\"pipeline_manifest_hash\":\"9d9f973085559f55e7ab1a93444dde20a80f3ffa330bd7212dd894e481d7c939\",\"purpose\":\"clinical_care\"}\n",
      "Training experiment recorded: a74279d9-8eec-4631-a1ef-582df39ee059\n",
      "Ledger integrity OK? True None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demo()\n",
    "# if __name__ == \"__main__\":\n",
    "#     demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "404ee677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from typing import Dict, Any\n",
    "\n",
    "# ---------------------------------------\n",
    "# Defaults used by simulations\n",
    "# ---------------------------------------\n",
    "\n",
    "DEFAULT_PIPELINE = PipelineManifest(\n",
    "    pipeline_name=\"simulated_dermoscopy_pipeline\",\n",
    "    pipeline_version=\"sim-1.0\",\n",
    "    container_image=None,\n",
    "    code_commit=\"sim_commit\",\n",
    "    parameters={\"img_size\": 512, \"threshold\": 0.5},\n",
    "    dependencies={\"python\": \"3.11\"}\n",
    ")\n",
    "\n",
    "DEFAULT_MODEL = ModelSpec(\n",
    "    model_name=\"simulated_model\",\n",
    "    model_version=\"0.1\",\n",
    "    weights_hash=\"0\" * 64,\n",
    "    framework=\"pytorch\",\n",
    "    extra={\"note\": \"simulation\"}\n",
    ")\n",
    "\n",
    "def simulate_workload(overlay, n_runs=200, tamper_rate=0.1, revoke_at=120) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simulate realistic clinical AI workload with mixed access patterns.\n",
    "    \n",
    "    This function simulates a healthcare environment with:\n",
    "    - Multiple users with different roles (dermatologist, engineer, guest)\n",
    "    - Different purposes (clinical care, research)\n",
    "    - Consent revocation mid-simulation\n",
    "    - Optional ledger tampering (for testing integrity checks)\n",
    "    \n",
    "    Tracks:\n",
    "    - How many inferences executed successfully\n",
    "    - How many were blocked by consent\n",
    "    - Ledger integrity status\n",
    "    - Reproducibility manifest count\n",
    "    \n",
    "    Args:\n",
    "        overlay: GovernanceOverlay instance to test\n",
    "        n_runs: Number of inference attempts to simulate\n",
    "        tamper_rate: Probability of tampering (currently unused in this version)\n",
    "        revoke_at: Simulation step at which to revoke consent\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with execution statistics and integrity results\n",
    "    \"\"\"\n",
    "    roles = [\"dermatologist\", \"ml_engineer\", \"guest\"]\n",
    "    purposes = [\"clinical_care\", \"research\"]\n",
    "\n",
    "    blocked = 0\n",
    "    executed = 0\n",
    "    denied_events = 0\n",
    "\n",
    "    # For reproducibility scoring: store returned repro manifests\n",
    "    repro_manifests = []\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        # Revoke consent at a given time\n",
    "        if i == revoke_at:\n",
    "            try:\n",
    "                overlay.revoke_consent_policy(\"consent_001\", actor_id=\"admin\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        actor_role = random.choice(roles)\n",
    "        purpose = random.choice(purposes)\n",
    "\n",
    "        try:\n",
    "            repro = overlay.record_inference(\n",
    "                actor_id=f\"user_{i}\",\n",
    "                actor_role=actor_role,\n",
    "                purpose=purpose,\n",
    "                consent_policy_id=\"consent_001\",\n",
    "                input_artifact_uri=f\"s3://bucket/patient/visit{i}/img.jpg\",\n",
    "                input_artifact_hash=f\"{i:064x}\",  # simulated hash\n",
    "                output_artifacts={\"report_json\": (f\"s3://bucket/patient/visit{i}/report.json\", f\"{(i+1):064x}\")},\n",
    "                pipeline_manifest=DEFAULT_PIPELINE,\n",
    "                model_spec=DEFAULT_MODEL,\n",
    "            )\n",
    "            executed += 1\n",
    "            repro_manifests.append(repro)\n",
    "        except PermissionError:\n",
    "            blocked += 1\n",
    "            denied_events += 1\n",
    "        except Exception:\n",
    "            # other errors\n",
    "            pass\n",
    "\n",
    "    # Integrity check (only meaningful for ledger variants)\n",
    "    ok, err = overlay.ledger.verify_integrity()\n",
    "\n",
    "    return {\n",
    "        \"executed\": executed,\n",
    "        \"blocked\": blocked,\n",
    "        \"denied_events\": denied_events,\n",
    "        \"ledger_integrity_ok\": ok,\n",
    "        \"ledger_integrity_error\": err,\n",
    "        \"n_repro_manifests\": len(repro_manifests),\n",
    "    }\n",
    "\n",
    "\n",
    "def tamper_ledger_file(path: str, flip_probability: float = 0.2):\n",
    "    \"\"\"\n",
    "    Intentionally tamper with ledger to test integrity detection.\n",
    "    \n",
    "    This function simulates an attacker or accidental corruption:\n",
    "    - Randomly selects an entry from the ledger\n",
    "    - Modifies its payload (adds/changes fields)\n",
    "    - Writes corrupted version back to disk\n",
    "    \n",
    "    If integrity checking works correctly, this should be detected\n",
    "    by verify_integrity() since it breaks the hash chain.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to ledger file to tamper with\n",
    "        flip_probability: Probability of adding \"tampered\" flag vs changing purpose\n",
    "        \n",
    "    Returns:\n",
    "        True if tampering succeeded, False if no valid entries to tamper\n",
    "    \"\"\"\n",
    "    import json\n",
    "    lines = open(path, \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "    candidates = [idx for idx, ln in enumerate(lines) if '\"entry_hash\"' in ln]\n",
    "\n",
    "    if not candidates:\n",
    "        return False\n",
    "\n",
    "    idx = random.choice(candidates)\n",
    "    obj = json.loads(lines[idx])\n",
    "\n",
    "    # mutate a field\n",
    "    if random.random() < flip_probability:\n",
    "        obj[\"payload\"][\"tampered\"] = True\n",
    "    else:\n",
    "        obj[\"payload\"][\"purpose\"] = \"tampered_purpose\"\n",
    "\n",
    "    lines[idx] = json.dumps(obj, ensure_ascii=False)\n",
    "    open(path, \"w\", encoding=\"utf-8\").write(\"\\n\".join(lines) + \"\\n\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7044e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Off-ledger reproducibility manifest verification\n",
    "# ---------------------------------------\n",
    "\n",
    "def list_inference_events(ledger_path: str):\n",
    "    \"\"\"\n",
    "    Extract all inference events from ledger.\n",
    "    \n",
    "    Scans ledger file and collects metadata about all\n",
    "    INFERENCE_EXECUTED events. Useful for:\n",
    "    - Audit reports (how many inferences ran)\n",
    "    - Batch verification (check reproducibility of all events)\n",
    "    - Usage analytics\n",
    "    \n",
    "    Args:\n",
    "        ledger_path: Path to ledger file\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with event_id, repro_manifest_hash,\n",
    "        entry_id, and timestamp_ms for each inference event\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    with open(ledger_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            row = json.loads(line)\n",
    "            if row.get(\"event_type\") == \"INFERENCE_EXECUTED\":\n",
    "                payload = row.get(\"payload\", {})\n",
    "                events.append({\n",
    "                    \"event_id\": payload.get(\"event_id\"),\n",
    "                    \"repro_manifest_hash\": payload.get(\"repro_manifest_hash\"),\n",
    "                    \"entry_id\": row.get(\"entry_id\"),\n",
    "                    \"timestamp_ms\": row.get(\"timestamp_ms\"),\n",
    "                })\n",
    "    return events\n",
    "\n",
    "\n",
    "def get_inference_event(ledger_path: str, event_id: str):\n",
    "    \"\"\"\n",
    "    Retrieve a specific inference event by ID.\n",
    "    \n",
    "    Args:\n",
    "        ledger_path: Path to ledger file\n",
    "        event_id: UUID of inference event to find\n",
    "        \n",
    "    Returns:\n",
    "        Full ledger entry dictionary, or None if not found\n",
    "    \"\"\"\n",
    "    with open(ledger_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            row = json.loads(line)\n",
    "            if row.get(\"event_type\") == \"INFERENCE_EXECUTED\":\n",
    "                payload = row.get(\"payload\", {})\n",
    "                if payload.get(\"event_id\") == event_id:\n",
    "                    return row\n",
    "    return None\n",
    "\n",
    "\n",
    "def verify_repro_manifest_against_ledger(\n",
    "    ledger_path: str,\n",
    "    manifest_store_dir: str,\n",
    "    event_id: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify that off-ledger reproducibility manifest matches on-ledger hash.\n",
    "    \n",
    "    This is critical for detecting tampering with off-ledger storage.\n",
    "    Process:\n",
    "    1. Find inference event in ledger (contains manifest hash)\n",
    "    2. Load manifest from off-ledger storage\n",
    "    3. Compute manifest hash locally\n",
    "    4. Compare: local hash vs ledger hash\n",
    "    \n",
    "    If hashes don't match, manifest has been tampered with.\n",
    "    \n",
    "    This provides two-tier verification:\n",
    "    - Ledger integrity (via hash chain)\n",
    "    - Manifest integrity (via hash comparison)\n",
    "    \n",
    "    Args:\n",
    "        ledger_path: Path to ledger file\n",
    "        manifest_store_dir: Directory with manifest files\n",
    "        event_id: UUID of inference event to verify\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - ok: True if verification passed\n",
    "        - reason: Error message if verification failed\n",
    "        - ledger_repro_hash: Hash stored on ledger\n",
    "        - local_repro_hash: Hash computed from local file\n",
    "        - manifest_path: Path to manifest file\n",
    "    \"\"\"\n",
    "    entry = get_inference_event(ledger_path, event_id)\n",
    "    if entry is None:\n",
    "        return {\"ok\": False, \"reason\": \"No INFERENCE_EXECUTED event found\"}\n",
    "\n",
    "    ledger_hash = entry[\"payload\"].get(\"repro_manifest_hash\")\n",
    "    if not ledger_hash:\n",
    "        return {\"ok\": False, \"reason\": \"No repro_manifest_hash in ledger\"}\n",
    "\n",
    "    manifest_path = os.path.join(manifest_store_dir, f\"repro_{event_id}.json\")\n",
    "    if not os.path.exists(manifest_path):\n",
    "        return {\"ok\": False, \"reason\": \"Manifest file missing\"}\n",
    "\n",
    "    with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        manifest_obj = json.loads(f.read())\n",
    "\n",
    "    local_hash = hashlib.sha256(\n",
    "        json.dumps(\n",
    "            manifest_obj,\n",
    "            sort_keys=True,\n",
    "            separators=(\",\", \":\"),\n",
    "            ensure_ascii=False\n",
    "        ).encode(\"utf-8\")\n",
    "    ).hexdigest()\n",
    "\n",
    "    return {\n",
    "        \"ok\": local_hash == ledger_hash,\n",
    "        \"event_id\": event_id,\n",
    "        \"ledger_repro_hash\": ledger_hash,\n",
    "        \"local_repro_hash\": local_hash,\n",
    "        \"manifest_path\": manifest_path,\n",
    "    }\n",
    "\n",
    "\n",
    "def tamper_repro_manifest(manifest_store_dir: str, event_id: str):\n",
    "    \"\"\"\n",
    "    Intentionally corrupt a reproducibility manifest for testing.\n",
    "    \n",
    "    Simulates attacker or accidental corruption of off-ledger storage.\n",
    "    Adds fake fields and changes values.\n",
    "    \n",
    "    If verification works correctly, this should be detected by\n",
    "    verify_repro_manifest_against_ledger() since hash won't match ledger.\n",
    "    \n",
    "    Args:\n",
    "        manifest_store_dir: Directory containing manifests\n",
    "        event_id: UUID of event whose manifest to corrupt\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If manifest doesn't exist\n",
    "    \"\"\"\n",
    "    manifest_path = os.path.join(manifest_store_dir, f\"repro_{event_id}.json\")\n",
    "    if not os.path.exists(manifest_path):\n",
    "        raise FileNotFoundError(manifest_path)\n",
    "\n",
    "    with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.loads(f.read())\n",
    "\n",
    "    # Intentional tampering\n",
    "    obj[\"tampered\"] = True\n",
    "    obj[\"purpose\"] = \"tampered_purpose\"\n",
    "\n",
    "    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, sort_keys=True, separators=(\",\", \":\"), ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3af86c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ablation results (no tampering) ===\n",
      "executed: 77\n",
      "blocked: 123\n",
      "denied_events: 123\n",
      "ledger_integrity_ok: True\n",
      "ledger_integrity_error: None\n",
      "n_repro_manifests: 77\n",
      "\n",
      "=== After tampering ===\n",
      "Ledger integrity OK? False\n",
      "Error: Hash mismatch at entry 22f3a690-2e54-444c-9661-d5bcdf75e4cc\n"
     ]
    }
   ],
   "source": [
    "def run_ablation():\n",
    "    \"\"\"\n",
    "    Run ablation study to test governance system components.\n",
    "    \n",
    "    Ablation study isolates and tests specific features:\n",
    "    1. Baseline: Run simulation with no tampering\n",
    "    2. Verify: Check ledger integrity (should pass)\n",
    "    3. Tamper: Corrupt ledger\n",
    "    4. Re-verify: Check integrity again (should fail)\n",
    "    \n",
    "    This validates that:\n",
    "    - Consent enforcement works (some requests blocked)\n",
    "    - Audit trail is complete\n",
    "    - Integrity checking detects tampering\n",
    "    \n",
    "    Prints results showing executed vs blocked inferences,\n",
    "    ledger integrity before and after tampering.\n",
    "    \"\"\"\n",
    "    # Fresh ledger each run\n",
    "    ledger_path = \"{ARCHIVE_DIR}/ledger/ablation_ledger.jsonl\"\n",
    "    if os.path.exists(ledger_path):\n",
    "        os.remove(ledger_path)\n",
    "\n",
    "    ledger = LocalLedger(ledger_path)\n",
    "    overlay = GovernanceOverlay(ledger)\n",
    "\n",
    "    # Create consent policy\n",
    "    policy = ConsentPolicy(\n",
    "        policy_id=\"consent_001\",\n",
    "        subject_id=\"patient_sim\",\n",
    "        allowed_purposes=[\"clinical_care\", \"research\"],\n",
    "        allowed_roles=[\"dermatologist\", \"ml_engineer\"],\n",
    "        valid_from_ms=now_epoch_ms() - 1000,\n",
    "        valid_until_ms=None,\n",
    "        revocable=True,\n",
    "        revoked=False,\n",
    "        version=1\n",
    "    )\n",
    "    overlay.store_consent_policy(policy)\n",
    "\n",
    "    # --- Run simulation ---\n",
    "    results = simulate_workload(\n",
    "        overlay,\n",
    "        n_runs=200,\n",
    "        tamper_rate=0.1,\n",
    "        revoke_at=120\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Ablation results (no tampering) ===\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # --- Tamper and re-verify ---\n",
    "    tamper_ledger_file(ledger_path)\n",
    "    ok, err = ledger.verify_integrity()\n",
    "\n",
    "    print(\"\\n=== After tampering ===\")\n",
    "    print(\"Ledger integrity OK?\", ok)\n",
    "    print(\"Error:\", err)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "run_ablation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511f54fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archived results to: results_20251219_225234\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Archive results for later analysis.\n",
    "\n",
    "Creates timestamped directory and copies:\n",
    "- Manifest store (off-ledger reproducibility receipts)\n",
    "- Ledger (on-ledger audit trail)\n",
    "- Policy store (consent policies)\n",
    "\n",
    "This enables:\n",
    "- Historical analysis (compare governance over time)\n",
    "- Compliance documentation (preserve audit evidence)\n",
    "- Reproducibility (reconstruct past system state)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# shutil.copytree(\"./manifest_store\", f\"{ARCHIVE_DIR}/manifest_store\")\n",
    "# shutil.copytree(\"./ledger\", f\"{ARCHIVE_DIR}/ledger\")\n",
    "# shutil.copytree(\"./policy_store\", f\"{ARCHIVE_DIR}/policy_store\")\n",
    "\n",
    "print(\"Archived results to:\", ARCHIVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc27316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, os, json\n",
    "from dataclasses import asdict\n",
    "\n",
    "def random_policy(i, t0_ms):\n",
    "    \"\"\"\n",
    "    Generate diverse consent policies for simulation.\n",
    "    \n",
    "    Creates realistic mix of policy types:\n",
    "    - Clinical-only: Only for patient care\n",
    "    - Clinical + research: Dual-use authorization\n",
    "    - Expiring: Time-limited consent\n",
    "    - Non-revocable: Cannot be withdrawn (rare, institutional research)\n",
    "    \n",
    "    Weighted distribution mimics real healthcare environment\n",
    "    where most consent is clinical-focused.\n",
    "    \n",
    "    Args:\n",
    "        i: Policy index (used for unique IDs)\n",
    "        t0_ms: Base timestamp for policy validity\n",
    "        \n",
    "    Returns:\n",
    "        ConsentPolicy with randomized but realistic attributes\n",
    "    \"\"\"\n",
    "\n",
    "    policy_id = f\"consent_{i:04d}\"\n",
    "    subject_id = f\"patient_{i:04d}\"\n",
    "\n",
    "    # Mix policy types\n",
    "    kind = random.choices(\n",
    "        [\"clinical_only\", \"clinical_research\", \"expires_fast\", \"non_revocable\"],\n",
    "        weights=[0.45, 0.35, 0.15, 0.05],\n",
    "        k=1\n",
    "    )[0]\n",
    "\n",
    "    allowed_roles = [\"dermatologist\", \"ml_engineer\"]\n",
    "    allowed_purposes = [\"clinical_care\"]\n",
    "\n",
    "    valid_until = None\n",
    "    revocable = True\n",
    "\n",
    "    if kind == \"clinical_research\":\n",
    "        allowed_purposes = [\"clinical_care\", \"research\"]\n",
    "    elif kind == \"expires_fast\":\n",
    "        allowed_purposes = [\"clinical_care\", \"research\"]\n",
    "        valid_until = t0_ms + random.randint(10_000, 60_000)  # expires within 10-60s\n",
    "    elif kind == \"non_revocable\":\n",
    "        allowed_purposes = [\"clinical_care\"]\n",
    "        revocable = False\n",
    "\n",
    "    return ConsentPolicy(\n",
    "        policy_id=policy_id,\n",
    "        subject_id=subject_id,\n",
    "        allowed_purposes=allowed_purposes,\n",
    "        allowed_roles=allowed_roles,\n",
    "        valid_from_ms=t0_ms - 1000,\n",
    "        valid_until_ms=valid_until,\n",
    "        revocable=revocable,\n",
    "        revoked=False,\n",
    "        version=1\n",
    "    )\n",
    "\n",
    "def generate_actor():\n",
    "    \"\"\"\n",
    "    Generate random actor (user) for access simulation.\n",
    "    \n",
    "    Creates diverse mix of:\n",
    "    - Authorized roles (dermatologist, ml_engineer) - most common\n",
    "    - Unauthorized roles (guest, nurse) - some attempts should fail\n",
    "    - Mixed purposes (clinical_care dominant, some research)\n",
    "    \n",
    "    Weighted distribution models real access patterns.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (role: str, purpose: str)\n",
    "    \"\"\"\n",
    "    roles = [\"dermatologist\", \"ml_engineer\", \"guest\", \"nurse\", \"admin\"]\n",
    "    role = random.choices(roles, weights=[0.55, 0.18, 0.12, 0.10, 0.05], k=1)[0]\n",
    "    purpose = random.choices([\"clinical_care\", \"research\"], weights=[0.75, 0.25], k=1)[0]\n",
    "    return role, purpose\n",
    "\n",
    "def run_scenario(\n",
    "    overlay,\n",
    "    n_patients=200,\n",
    "    n_runs=1000,\n",
    "    revoke_prob=0.02,\n",
    "    tamper_after=False,\n",
    "    seed=7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run comprehensive governance scenario with multiple patients.\n",
    "    \n",
    "    This is the main simulation function for testing governance at scale.\n",
    "    It models a realistic clinical AI deployment:\n",
    "    \n",
    "    1. Many patients (each with their own consent policy)\n",
    "    2. Many inference runs (clinical + research uses)\n",
    "    3. Dynamic consent (policies can be revoked mid-simulation)\n",
    "    4. Mixed authorization (authorized + unauthorized attempts)\n",
    "    5. Optional tampering (test integrity detection)\n",
    "    \n",
    "    Tracks detailed metrics:\n",
    "    - Execution counts (successful vs blocked)\n",
    "    - Unauthorized access attempts and blocks\n",
    "    - Post-revocation executions (should not happen)\n",
    "    - Governance overhead (time per operation)\n",
    "    - Audit completeness (all events logged)\n",
    "    - Ledger integrity (before/after tampering)\n",
    "    \n",
    "    Args:\n",
    "        overlay: GovernanceOverlay instance\n",
    "        n_patients: Number of unique patients/policies to create\n",
    "        n_runs: Number of inference attempts to simulate\n",
    "        revoke_prob: Probability of revoking consent at each step\n",
    "        tamper_after: Whether to tamper with ledger after simulation\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with comprehensive statistics about execution,\n",
    "        consent enforcement, audit completeness, and integrity\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    t0 = now_epoch_ms()\n",
    "\n",
    "    # Create policies for many patients\n",
    "    policy_ids = []\n",
    "    for i in range(n_patients):\n",
    "        p = random_policy(i, t0)\n",
    "        overlay.store_consent_policy(p)\n",
    "        policy_ids.append(p.policy_id)\n",
    "\n",
    "    # Stats\n",
    "    stats = {\n",
    "        \"executed\": 0,\n",
    "        \"blocked\": 0,\n",
    "        \"attempted_unauthorized\": 0,\n",
    "        \"blocked_unauthorized\": 0,\n",
    "        \"post_revoke_exec\": 0,\n",
    "        \"events_expected\": 0,\n",
    "        \"events_actual\": 0,\n",
    "        \"governance_time_ms\": 0,\n",
    "    }\n",
    "\n",
    "    # Keep track of revoked policies (ground truth)\n",
    "    revoked = set()\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        policy_id = random.choice(policy_ids)\n",
    "        actor_role, purpose = generate_actor()\n",
    "        actor_id = f\"{actor_role}_{random.randint(1,5000)}\"\n",
    "\n",
    "        # Random revocation events\n",
    "        if random.random() < revoke_prob:\n",
    "            try:\n",
    "                overlay.revoke_consent_policy(policy_id, actor_id=\"admin_sim\")\n",
    "                revoked.add(policy_id)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Simulated artifacts\n",
    "        input_uri = f\"s3://bucket/{policy_id}/visit{i}/img.jpg\"\n",
    "        input_hash = f\"{random.getrandbits(256):064x}\"\n",
    "        out_uri = f\"s3://bucket/{policy_id}/visit{i}/report.json\"\n",
    "        out_hash = f\"{random.getrandbits(256):064x}\"\n",
    "\n",
    "        # Define \"unauthorized\" attempts (by policy rules)\n",
    "        # We'll count guest/nurse as usually unauthorized\n",
    "        unauthorized_attempt = actor_role in {\"guest\", \"nurse\"}\n",
    "        if unauthorized_attempt:\n",
    "            stats[\"attempted_unauthorized\"] += 1\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            overlay.record_inference(\n",
    "                actor_id=actor_id,\n",
    "                actor_role=actor_role,\n",
    "                purpose=purpose,\n",
    "                consent_policy_id=policy_id,\n",
    "                input_artifact_uri=input_uri,\n",
    "                input_artifact_hash=input_hash,\n",
    "                output_artifacts={\"report_json\": (out_uri, out_hash)},\n",
    "                pipeline_manifest=DEFAULT_PIPELINE,\n",
    "                model_spec=DEFAULT_MODEL,\n",
    "            )\n",
    "            stats[\"executed\"] += 1\n",
    "\n",
    "            if policy_id in revoked:\n",
    "                # if it still executed after revocation, thatâ€™s a drift incident\n",
    "                stats[\"post_revoke_exec\"] += 1\n",
    "\n",
    "        except PermissionError:\n",
    "            stats[\"blocked\"] += 1\n",
    "            if unauthorized_attempt:\n",
    "                stats[\"blocked_unauthorized\"] += 1\n",
    "        finally:\n",
    "            stats[\"governance_time_ms\"] += (time.perf_counter() - start) * 1000\n",
    "\n",
    "        # Audit completeness expectation:\n",
    "        # For each run we expect at least an INFERENCE_EXECUTED or CONSENT_DENIED event\n",
    "        stats[\"events_expected\"] += 1\n",
    "\n",
    "    # Count actual entries (excluding genesis)\n",
    "    rows = overlay.ledger._read_all_raw()\n",
    "    stats[\"events_actual\"] = sum(1 for r in rows if \"entry_hash\" in r)\n",
    "\n",
    "    # Integrity check before optional tampering\n",
    "    ok_before, err_before = overlay.ledger.verify_integrity()\n",
    "\n",
    "    if tamper_after:\n",
    "        tamper_ledger_file(overlay.ledger.ledger_path)\n",
    "        ok_after, err_after = overlay.ledger.verify_integrity()\n",
    "    else:\n",
    "        ok_after, err_after = ok_before, err_before\n",
    "\n",
    "    stats.update({\n",
    "        \"ledger_integrity_ok_before\": ok_before,\n",
    "        \"ledger_integrity_err_before\": err_before,\n",
    "        \"ledger_integrity_ok_after\": ok_after,\n",
    "        \"ledger_integrity_err_after\": err_after,\n",
    "        \"unauthorized_block_rate\": (stats[\"blocked_unauthorized\"] / max(1, stats[\"attempted_unauthorized\"])),\n",
    "        \"avg_governance_ms_per_run\": (stats[\"governance_time_ms\"] / max(1, n_runs)),\n",
    "        \"ledger_entries\": stats[\"events_actual\"],\n",
    "    })\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0644cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'executed': 321,\n",
       "  'blocked': 179,\n",
       "  'attempted_unauthorized': 115,\n",
       "  'blocked_unauthorized': 115,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 500,\n",
       "  'events_actual': 550,\n",
       "  'governance_time_ms': 626.4125380018868,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': True,\n",
       "  'ledger_integrity_err_after': None,\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 1.2528250760037736,\n",
       "  'ledger_entries': 550,\n",
       "  'scenario': \"{'n_patients': 50, 'n_runs': 500, 'revoke_prob': 0.0, 'tamper_after': False, 'seed': 1}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_1.jsonl'},\n",
       " {'executed': 1140,\n",
       "  'blocked': 860,\n",
       "  'attempted_unauthorized': 411,\n",
       "  'blocked_unauthorized': 411,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 2000,\n",
       "  'events_actual': 2236,\n",
       "  'governance_time_ms': 8774.79608199849,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': True,\n",
       "  'ledger_integrity_err_after': None,\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 4.387398040999245,\n",
       "  'ledger_entries': 2236,\n",
       "  'scenario': \"{'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.02, 'tamper_after': False, 'seed': 2}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_2.jsonl'},\n",
       " {'executed': 2384,\n",
       "  'blocked': 2616,\n",
       "  'attempted_unauthorized': 1097,\n",
       "  'blocked_unauthorized': 1097,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 5000,\n",
       "  'events_actual': 5742,\n",
       "  'governance_time_ms': 56895.342478001956,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': True,\n",
       "  'ledger_integrity_err_after': None,\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 11.379068495600391,\n",
       "  'ledger_entries': 5742,\n",
       "  'scenario': \"{'n_patients': 500, 'n_runs': 5000, 'revoke_prob': 0.05, 'tamper_after': False, 'seed': 3}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_3.jsonl'},\n",
       " {'executed': 447,\n",
       "  'blocked': 1553,\n",
       "  'attempted_unauthorized': 462,\n",
       "  'blocked_unauthorized': 462,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 2000,\n",
       "  'events_actual': 2571,\n",
       "  'governance_time_ms': 8436.241800998234,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': True,\n",
       "  'ledger_integrity_err_after': None,\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 4.218120900499117,\n",
       "  'ledger_entries': 2571,\n",
       "  'scenario': \"{'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.2, 'tamper_after': False, 'seed': 5}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_5.jsonl'},\n",
       " {'executed': 865,\n",
       "  'blocked': 4135,\n",
       "  'attempted_unauthorized': 1098,\n",
       "  'blocked_unauthorized': 1098,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 5000,\n",
       "  'events_actual': 6897,\n",
       "  'governance_time_ms': 55453.58840999534,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': True,\n",
       "  'ledger_integrity_err_after': None,\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 11.090717681999068,\n",
       "  'ledger_entries': 6897,\n",
       "  'scenario': \"{'n_patients': 500, 'n_runs': 5000, 'revoke_prob': 0.3, 'tamper_after': False, 'seed': 6}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_6.jsonl'},\n",
       " {'executed': 6787,\n",
       "  'blocked': 13213,\n",
       "  'attempted_unauthorized': 4322,\n",
       "  'blocked_unauthorized': 4322,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 20000,\n",
       "  'events_actual': 21981,\n",
       "  'governance_time_ms': 858074.89715201,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': True,\n",
       "  'ledger_integrity_err_after': None,\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 42.9037448576005,\n",
       "  'ledger_entries': 21981,\n",
       "  'scenario': \"{'n_patients': 1000, 'n_runs': 20000, 'revoke_prob': 0.05, 'tamper_after': False, 'seed': 7}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_7.jsonl'},\n",
       " {'executed': 1090,\n",
       "  'blocked': 910,\n",
       "  'attempted_unauthorized': 426,\n",
       "  'blocked_unauthorized': 426,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 2000,\n",
       "  'events_actual': 2245,\n",
       "  'governance_time_ms': 8632.96680499252,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': False,\n",
       "  'ledger_integrity_err_after': 'Hash mismatch at entry 85b06689-2aef-4e91-8512-fec632fa793e',\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 4.31648340249626,\n",
       "  'ledger_entries': 2245,\n",
       "  'scenario': \"{'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.02, 'tamper_after': True, 'seed': 4}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_4.jsonl'},\n",
       " {'executed': 1148,\n",
       "  'blocked': 852,\n",
       "  'attempted_unauthorized': 429,\n",
       "  'blocked_unauthorized': 429,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 2000,\n",
       "  'events_actual': 2238,\n",
       "  'governance_time_ms': 8660.814725994669,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': False,\n",
       "  'ledger_integrity_err_after': 'Hash mismatch at entry e9a3c868-47e8-4f33-ab41-7a6d06ffa1cc',\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 4.3304073629973345,\n",
       "  'ledger_entries': 2238,\n",
       "  'scenario': \"{'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.02, 'tamper_after': True, 'seed': 8}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_8.jsonl'},\n",
       " {'executed': 2285,\n",
       "  'blocked': 2715,\n",
       "  'attempted_unauthorized': 1095,\n",
       "  'blocked_unauthorized': 1095,\n",
       "  'post_revoke_exec': 0,\n",
       "  'events_expected': 5000,\n",
       "  'events_actual': 5750,\n",
       "  'governance_time_ms': 54785.54382299982,\n",
       "  'ledger_integrity_ok_before': True,\n",
       "  'ledger_integrity_err_before': None,\n",
       "  'ledger_integrity_ok_after': False,\n",
       "  'ledger_integrity_err_after': 'Hash mismatch at entry 4ee32bf8-8562-4aca-a28d-391a240a3078',\n",
       "  'unauthorized_block_rate': 1.0,\n",
       "  'avg_governance_ms_per_run': 10.957108764599964,\n",
       "  'ledger_entries': 5750,\n",
       "  'scenario': \"{'n_patients': 500, 'n_runs': 5000, 'revoke_prob': 0.05, 'tamper_after': True, 'seed': 9}\",\n",
       "  'ledger_path': 'results_20251219_225234/ledger/scenario_seed_9.jsonl'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run multiple governance scenarios with different parameters.\n",
    "\n",
    "Each scenario tests different aspects:\n",
    "- Small scale (50 patients, 500 runs) - baseline functionality\n",
    "- Medium scale (200 patients, 2000 runs) - realistic load with revocations\n",
    "- Large scale (500 patients, 5000 runs) - stress test (commented out)\n",
    "- Tampering test (with tamper_after=True) - integrity detection (commented out)\n",
    "\n",
    "Results show how governance system behaves under various conditions.\n",
    "\"\"\"\n",
    "\n",
    "scenarios = [\n",
    "  # Baselines (steady-state)\n",
    "  {\"n_patients\": 50,  \"n_runs\": 500,   \"revoke_prob\": 0.00, \"tamper_after\": False, \"seed\": 1},\n",
    "  {\"n_patients\": 200, \"n_runs\": 2000,  \"revoke_prob\": 0.02, \"tamper_after\": False, \"seed\": 2},\n",
    "  {\"n_patients\": 500, \"n_runs\": 5000,  \"revoke_prob\": 0.05, \"tamper_after\": False, \"seed\": 3},\n",
    "\n",
    "  # Consent stress\n",
    "  {\"n_patients\": 200, \"n_runs\": 2000,  \"revoke_prob\": 0.20, \"tamper_after\": False, \"seed\": 5},\n",
    "  {\"n_patients\": 500, \"n_runs\": 5000,  \"revoke_prob\": 0.30, \"tamper_after\": False, \"seed\": 6},\n",
    "\n",
    "  # Performance stress (scale)\n",
    "  {\"n_patients\": 1000,\"n_runs\": 20000, \"revoke_prob\": 0.05, \"tamper_after\": False, \"seed\": 7},\n",
    "\n",
    "  # Integrity stress (repeat tamper, multiple seeds)\n",
    "  {\"n_patients\": 200, \"n_runs\": 2000,  \"revoke_prob\": 0.02, \"tamper_after\": True,  \"seed\": 4},\n",
    "  {\"n_patients\": 200, \"n_runs\": 2000,  \"revoke_prob\": 0.02, \"tamper_after\": True,  \"seed\": 8},\n",
    "  {\"n_patients\": 500, \"n_runs\": 5000,  \"revoke_prob\": 0.05, \"tamper_after\": True,  \"seed\": 9},\n",
    "]\n",
    "results = []\n",
    "for s in scenarios:\n",
    "    # fresh ledger each scenario (important)\n",
    "    ledger_path = f\"{ARCHIVE_DIR}/ledger/scenario_seed_{s['seed']}.jsonl\"\n",
    "    if os.path.exists(ledger_path):\n",
    "        os.remove(ledger_path)\n",
    "\n",
    "    ledger = LocalLedger(ledger_path)\n",
    "    overlay = GovernanceOverlay(ledger)\n",
    "\n",
    "    res = run_scenario(overlay, **s)\n",
    "    res[\"scenario\"] = str(s)\n",
    "    res[\"ledger_path\"] = ledger_path  # helpful for traceability\n",
    "    results.append(res)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f81367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scenario_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# results = run_scenario(...)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{ARCHIVE_DIR}/scenario_metrics.json', \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Saved scenario_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9fa1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch_offledger_tamper_test(\n",
    "    overlay,\n",
    "    sample_size=200,\n",
    "    tamper_fraction=0.25,\n",
    "    seed=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Test off-ledger manifest integrity detection at scale.\n",
    "    \n",
    "    This function validates the two-tier security model:\n",
    "    1. Ledger is tamper-evident (via hash chain)\n",
    "    2. Manifests are tamper-evident (via hash comparison with ledger)\n",
    "    \n",
    "    Process:\n",
    "    1. Sample random inference events from ledger\n",
    "    2. Verify all manifests (baseline - should all pass)\n",
    "    3. Tamper with fraction of manifests (simulate attack/corruption)\n",
    "    4. Re-verify all manifests\n",
    "    5. Count: detected tampering, missed tampering, false alarms\n",
    "    \n",
    "    Good governance system should:\n",
    "    - Detect all tampering (high detection rate)\n",
    "    - No false alarms (specificity = 100%)\n",
    "    - Fast verification (scalable)\n",
    "    \n",
    "    Args:\n",
    "        overlay: GovernanceOverlay instance with populated ledger\n",
    "        sample_size: How many events to test (max)\n",
    "        tamper_fraction: Proportion of manifests to corrupt (0.0 to 1.0)\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - Total inference events available\n",
    "        - Sample size tested\n",
    "        - Number tampered with\n",
    "        - Baseline verification (before tampering)\n",
    "        - Detection statistics (detected, missed, false alarms)\n",
    "        - Detection rate (should be ~100%)\n",
    "        - False alarm rate (should be ~0%)\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    ledger_path = overlay.ledger.ledger_path\n",
    "    manifest_dir = overlay.manifest_store_dir\n",
    "\n",
    "    events = list_inference_events(ledger_path)\n",
    "    if len(events) == 0:\n",
    "        raise ValueError(\"No inference events found\")\n",
    "\n",
    "    sample = random.sample(events, k=min(sample_size, len(events)))\n",
    "    tamper_n = int(len(sample) * tamper_fraction)\n",
    "\n",
    "    to_tamper = set(e[\"event_id\"] for e in random.sample(sample, k=tamper_n))\n",
    "\n",
    "    baseline_ok = 0\n",
    "    for e in sample:\n",
    "        res = verify_repro_manifest_against_ledger(\n",
    "            ledger_path, manifest_dir, e[\"event_id\"]\n",
    "        )\n",
    "        baseline_ok += int(res[\"ok\"])\n",
    "\n",
    "    detected = 0\n",
    "    missed = 0\n",
    "    false_alarm = 0\n",
    "\n",
    "    for e in sample:\n",
    "        eid = e[\"event_id\"]\n",
    "        if eid in to_tamper:\n",
    "            tamper_repro_manifest(manifest_dir, eid)\n",
    "\n",
    "        res = verify_repro_manifest_against_ledger(\n",
    "            ledger_path, manifest_dir, eid\n",
    "        )\n",
    "\n",
    "        if eid in to_tamper:\n",
    "            if res[\"ok\"] is False:\n",
    "                detected += 1\n",
    "            else:\n",
    "                missed += 1\n",
    "        else:\n",
    "            if res[\"ok\"] is False:\n",
    "                false_alarm += 1\n",
    "\n",
    "    return {\n",
    "        \"total_inference_events\": len(events),\n",
    "        \"sample_size\": len(sample),\n",
    "        \"tampered\": tamper_n,\n",
    "        \"baseline_ok_before\": baseline_ok,\n",
    "        \"detected_tamper\": detected,\n",
    "        \"missed_tamper\": missed,\n",
    "        \"false_alarms\": false_alarm,\n",
    "        \"tamper_detection_rate\": detected / max(1, tamper_n),\n",
    "        \"false_alarm_rate\": false_alarm / max(1, (len(sample) - tamper_n)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6fe3414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inference events: 2285\n",
      "Before tampering:\n",
      "{'ok': True, 'event_id': '3b85e42e-8f77-4dfb-9a95-c29a243667e1', 'ledger_repro_hash': '5714572298645178e7e7e5e8033ee6fe277bc6f85f0f2928527fc22443e731e1', 'local_repro_hash': '5714572298645178e7e7e5e8033ee6fe277bc6f85f0f2928527fc22443e731e1', 'manifest_path': 'results_20251219_225234/manifest_store/repro_3b85e42e-8f77-4dfb-9a95-c29a243667e1.json'}\n",
      "After tampering:\n",
      "{'ok': False, 'event_id': '3b85e42e-8f77-4dfb-9a95-c29a243667e1', 'ledger_repro_hash': '5714572298645178e7e7e5e8033ee6fe277bc6f85f0f2928527fc22443e731e1', 'local_repro_hash': '0ff082f88cf1d0908d7dd0b9d8cfff16e81ab7a32743c2bb1decb18bd54001fc', 'manifest_path': 'results_20251219_225234/manifest_store/repro_3b85e42e-8f77-4dfb-9a95-c29a243667e1.json'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Quick test of manifest verification (single event).\n",
    "\n",
    "Demonstrates:\n",
    "1. List all inference events from ledger\n",
    "2. Pick one event\n",
    "3. Verify its manifest (should pass initially)\n",
    "4. Tamper with manifest\n",
    "5. Re-verify (should now fail)\n",
    "\n",
    "This is a sanity check that verification logic works correctly.\n",
    "\"\"\"\n",
    "\n",
    "ledger_path = overlay.ledger.ledger_path\n",
    "manifest_dir = overlay.manifest_store_dir\n",
    "\n",
    "events = list_inference_events(ledger_path)\n",
    "print(\"Number of inference events:\", len(events))\n",
    "\n",
    "# Pick one event\n",
    "event_id = events[0][\"event_id\"]\n",
    "\n",
    "# Verify before tampering\n",
    "print(\"Before tampering:\")\n",
    "print(verify_repro_manifest_against_ledger(ledger_path, manifest_dir, event_id))\n",
    "\n",
    "# Tamper\n",
    "tamper_repro_manifest(manifest_dir, event_id)\n",
    "\n",
    "# Verify after tampering\n",
    "print(\"After tampering:\")\n",
    "print(verify_repro_manifest_against_ledger(ledger_path, manifest_dir, event_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88705c62",
   "metadata": {},
   "source": [
    "- In off-ledger tampering experiments, modifying the stored reproducibility manifest caused the locally computed hash to diverge from the immutable ledger commitment, resulting in deterministic detection of artifact corruption while leaving ledger integrity unaffected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05b7fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_inference_events': 2285,\n",
       " 'sample_size': 200,\n",
       " 'tampered': 50,\n",
       " 'baseline_ok_before': 200,\n",
       " 'detected_tamper': 50,\n",
       " 'missed_tamper': 0,\n",
       " 'false_alarms': 0,\n",
       " 'tamper_detection_rate': 1.0,\n",
       " 'false_alarm_rate': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Execute batch tampering test.\n",
    "\n",
    "Runs comprehensive test of off-ledger manifest integrity:\n",
    "- Tests 200 manifests\n",
    "- Tampers with 25% of them\n",
    "- Should detect nearly all tampering\n",
    "- Should have no false alarms\n",
    "\n",
    "Results show effectiveness of hash-based verification.\n",
    "\"\"\"\n",
    "\n",
    "result = batch_offledger_tamper_test(\n",
    "    overlay,\n",
    "    sample_size=200,\n",
    "    tamper_fraction=0.25,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5586bfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tamper_metrics.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save tamper detection metrics to JSON file.\n",
    "\n",
    "Preserves test results in archived directory for:\n",
    "- Documentation (prove governance system works)\n",
    "- Compliance (show validation testing)\n",
    "- Analysis (track metrics over time)\n",
    "\"\"\"\n",
    "\n",
    "with open(f'{ARCHIVE_DIR}/tamper_metrics.json', \"w\") as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(\"Saved tamper_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'executed': 321, 'blocked': 179, 'attempted_unauthorized': 115, 'blocked_unauthorized': 115, 'post_revoke_exec': 0, 'events_expected': 500, 'events_actual': 550, 'governance_time_ms': 608.4007529993869, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': True, 'ledger_integrity_err_after': None, 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 1.2168015059987738, 'ledger_entries': 550}\n",
      "{'executed': 1140, 'blocked': 860, 'attempted_unauthorized': 411, 'blocked_unauthorized': 411, 'post_revoke_exec': 0, 'events_expected': 2000, 'events_actual': 2236, 'governance_time_ms': 8917.088181003237, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': True, 'ledger_integrity_err_after': None, 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 4.4585440905016185, 'ledger_entries': 2236}\n",
      "{'executed': 2383, 'blocked': 2617, 'attempted_unauthorized': 1097, 'blocked_unauthorized': 1097, 'post_revoke_exec': 0, 'events_expected': 5000, 'events_actual': 5742, 'governance_time_ms': 56998.18455399835, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': True, 'ledger_integrity_err_after': None, 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 11.39963691079967, 'ledger_entries': 5742}\n",
      "{'executed': 447, 'blocked': 1553, 'attempted_unauthorized': 462, 'blocked_unauthorized': 462, 'post_revoke_exec': 0, 'events_expected': 2000, 'events_actual': 2571, 'governance_time_ms': 8041.560425001762, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': True, 'ledger_integrity_err_after': None, 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 4.020780212500881, 'ledger_entries': 2571}\n",
      "{'executed': 865, 'blocked': 4135, 'attempted_unauthorized': 1098, 'blocked_unauthorized': 1098, 'post_revoke_exec': 0, 'events_expected': 5000, 'events_actual': 6897, 'governance_time_ms': 53454.397307003484, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': True, 'ledger_integrity_err_after': None, 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 10.690879461400696, 'ledger_entries': 6897}\n",
      "{'executed': 6787, 'blocked': 13213, 'attempted_unauthorized': 4322, 'blocked_unauthorized': 4322, 'post_revoke_exec': 0, 'events_expected': 20000, 'events_actual': 21981, 'governance_time_ms': 863756.0566390007, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': True, 'ledger_integrity_err_after': None, 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 43.18780283195003, 'ledger_entries': 21981}\n",
      "{'executed': 1090, 'blocked': 910, 'attempted_unauthorized': 426, 'blocked_unauthorized': 426, 'post_revoke_exec': 0, 'events_expected': 2000, 'events_actual': 2245, 'governance_time_ms': 8832.793216997743, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': False, 'ledger_integrity_err_after': 'Hash mismatch at entry 1e47fe62-e640-4ead-b6fb-066cbb855689', 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 4.4163966084988715, 'ledger_entries': 2245}\n",
      "{'executed': 1148, 'blocked': 852, 'attempted_unauthorized': 429, 'blocked_unauthorized': 429, 'post_revoke_exec': 0, 'events_expected': 2000, 'events_actual': 2238, 'governance_time_ms': 9074.528053992253, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': False, 'ledger_integrity_err_after': 'Hash mismatch at entry c81e4da7-5944-47a8-9456-39cc7f4c61a9', 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 4.537264026996127, 'ledger_entries': 2238}\n",
      "{'executed': 2281, 'blocked': 2719, 'attempted_unauthorized': 1095, 'blocked_unauthorized': 1095, 'post_revoke_exec': 0, 'events_expected': 5000, 'events_actual': 5750, 'governance_time_ms': 56817.682176992406, 'ledger_integrity_ok_before': True, 'ledger_integrity_err_before': None, 'ledger_integrity_ok_after': False, 'ledger_integrity_err_after': 'Hash mismatch at entry 1f2049ef-4c7c-4baa-a523-44ef68468d48', 'unauthorized_block_rate': 1.0, 'avg_governance_ms_per_run': 11.363536435398482, 'ledger_entries': 5750}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Final integrity check of ledger.\n",
    "\n",
    "Verifies that the hash chain is intact.\n",
    "Should print: (True, None) if no tampering occurred.\n",
    "\"\"\"\n",
    "\n",
    "# for s in scenarios:\n",
    "#     ledger = LocalLedger(ledger_path)\n",
    "#     overlay = GovernanceOverlay(ledger)\n",
    "#     res = run_scenario(overlay, **s)\n",
    "#     print(res)\n",
    "\n",
    "for s in scenarios:\n",
    "    ledger_path = f\"{ARCHIVE_DIR}/ledger/scenario_seed_{s['seed']}.jsonl\"\n",
    "\n",
    "    if os.path.exists(ledger_path):\n",
    "        os.remove(ledger_path)\n",
    "\n",
    "    ledger = LocalLedger(ledger_path)\n",
    "    overlay = GovernanceOverlay(ledger)\n",
    "\n",
    "    res = run_scenario(overlay, **s)\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10db368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ledger Integrity Validation (All Scenarios) ===\n",
      "\n",
      "Scenario: {'n_patients': 50, 'n_runs': 500, 'revoke_prob': 0.0, 'tamper_after': False, 'seed': 1}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_1.jsonl\n",
      "Integrity OK? True\n",
      "\n",
      "Scenario: {'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.02, 'tamper_after': False, 'seed': 2}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_2.jsonl\n",
      "Integrity OK? True\n",
      "\n",
      "Scenario: {'n_patients': 500, 'n_runs': 5000, 'revoke_prob': 0.05, 'tamper_after': False, 'seed': 3}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_3.jsonl\n",
      "Integrity OK? True\n",
      "\n",
      "Scenario: {'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.2, 'tamper_after': False, 'seed': 5}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_5.jsonl\n",
      "Integrity OK? True\n",
      "\n",
      "Scenario: {'n_patients': 500, 'n_runs': 5000, 'revoke_prob': 0.3, 'tamper_after': False, 'seed': 6}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_6.jsonl\n",
      "Integrity OK? True\n",
      "\n",
      "Scenario: {'n_patients': 1000, 'n_runs': 20000, 'revoke_prob': 0.05, 'tamper_after': False, 'seed': 7}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_7.jsonl\n",
      "Integrity OK? True\n",
      "\n",
      "Scenario: {'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.02, 'tamper_after': True, 'seed': 4}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_4.jsonl\n",
      "Integrity OK? False\n",
      "Error: Hash mismatch at entry 1e47fe62-e640-4ead-b6fb-066cbb855689\n",
      "\n",
      "Scenario: {'n_patients': 200, 'n_runs': 2000, 'revoke_prob': 0.02, 'tamper_after': True, 'seed': 8}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_8.jsonl\n",
      "Integrity OK? False\n",
      "Error: Hash mismatch at entry c81e4da7-5944-47a8-9456-39cc7f4c61a9\n",
      "\n",
      "Scenario: {'n_patients': 500, 'n_runs': 5000, 'revoke_prob': 0.05, 'tamper_after': True, 'seed': 9}\n",
      "Ledger path: results_20251219_225234/ledger/scenario_seed_9.jsonl\n",
      "Integrity OK? False\n",
      "Error: Hash mismatch at entry 1f2049ef-4c7c-4baa-a523-44ef68468d48\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"=== Ledger Integrity Validation (All Scenarios) ===\")\n",
    "\n",
    "for res in results:\n",
    "    ledger_path = res[\"ledger_path\"]\n",
    "    ledger = LocalLedger(ledger_path)\n",
    "\n",
    "    ok, err = ledger.verify_integrity()\n",
    "\n",
    "    print(f\"\\nScenario: {res['scenario']}\")\n",
    "    print(f\"Ledger path: {ledger_path}\")\n",
    "    print(\"Integrity OK?\", ok)\n",
    "    if err:\n",
    "        print(\"Error:\", err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
